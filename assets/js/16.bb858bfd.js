(window.webpackJsonp=window.webpackJsonp||[]).push([[16],{490:function(t,s){t.exports="data:image/png;base64,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"},491:function(t,s,a){t.exports=a.p+"assets/img/b0e70a48.b0e70a48.png"},492:function(t,s,a){t.exports=a.p+"assets/img/6bf246e3.6bf246e3.png"},493:function(t,s,a){t.exports=a.p+"assets/img/1038f9db.1038f9db.png"},494:function(t,s,a){t.exports=a.p+"assets/img/fc3ad258.fc3ad258.png"},495:function(t,s,a){t.exports=a.p+"assets/img/87df71be.87df71be.png"},496:function(t,s,a){t.exports=a.p+"assets/img/b80859d4.b80859d4.gif"},600:function(t,s,a){"use strict";a.r(s);var n=a(5),e=Object(n.a)({},(function(){var t=this,s=t._self._c;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("p",[t._v("公司有一个业务需要抓取某网站数据，登录需要识别验证码，类似下面这种，这应该是很多网站使用的验证码类型。")]),t._v(" "),s("p",[s("img",{staticClass:"lazy",attrs:{alt:"","data-src":a(490),loading:"lazy"}})]),t._v(" "),s("p",[t._v("首先由于验证码比较简单，图像不复杂，而且全部是数字。于是试着采用传统方式，按照网上教程自己简单改了一个，使用 PHP 识别。大概流程就是切割二值化去噪等预处理，然后用字符串数组形式保存起来，识别传来的图片同样预处理后比较字符串的相似度，选出一个相识度最高的分类。识别率不是很理想（验证码比较简单，应该能优化得更好），隐约记得只能超过60%。")]),t._v(" "),s("p",[t._v("因为识别效果不理想，目标网站登录状态还是能保持很久，没必要花太多精力在这上面，于是找了一个人工打码服务。简直太便宜了，一个月花不了多少钱，效果还好，只是有时候延迟比较高。反正对于我们的业务来说是足够用了。")]),t._v(" "),s("p",[t._v("机器学习大潮来临，我寻思着能不能用在这上面，于是参考 TensorFlow 识别手写数字教程，开始照猫画虎。")]),t._v(" "),s("p",[t._v("本文描述的只是作为一个普通开发者的一些粗浅理解，"),s("strong",[t._v("所有的代码和数据均在文后的 GitHub 有存留")]),t._v("，建议结合代码阅读本文。如果有什么理解错误或 Bug 欢迎留言交流 ^_^")]),t._v(" "),s("h2",{attrs:{id:"tensorflow-是什么"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#tensorflow-是什么"}},[t._v("#")]),t._v(" TensorFlow 是什么")]),t._v(" "),s("p",[t._v("TensorFlow 是谷歌出的一款机器学习框架。看名字，TensorFlow 就是“张量流”。呃。。什么是张量呢？张量我的理解就是数据。张量有自己的形状，比如 0 阶张量是标量，1 阶是向量，2 阶是矩阵。。。所以在后文我们会看到在 TensorFlow 里面使用的量几乎都要定义其形状，因为它们都是张量。")]),t._v(" "),s("p",[t._v("我们可以把 TensorFlow 看作一个黑盒子，里面有一些架好的管道，喂给他一些“张量”，他吐出一些“张量”，吐出的东西就是我们需要的结果。")]),t._v(" "),s("p",[s("strong",[t._v("所以我们需要确定喂进去的是什么，吐出来的是什么，管道如何搭建。")])]),t._v(" "),s("p",[t._v("更多的入门概念可以查看这个 "),s("a",{attrs:{href:"https://keras-cn.readthedocs.io/en/latest/for_beginners/concepts/",target:"_blank",rel:"noopener noreferrer"}},[t._v("keras新手指南 » 一些基本概念"),s("OutboundLink")],1)]),t._v(" "),s("h2",{attrs:{id:"为什么使用-tensorflow"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#为什么使用-tensorflow"}},[t._v("#")]),t._v(" 为什么使用 TensorFlow")]),t._v(" "),s("p",[t._v("没别的什么原因，只是因为谷歌大名，也没想更多。先撸起袖子干起来。如果为了快速成型，我建议可以看一下 "),s("em",[t._v("Keras")]),t._v("，号称为人类设计的机器学习框架，也就是用户体验友好，提供好几个机器学习框架更高层的接口。")]),t._v(" "),s("h2",{attrs:{id:"大体流程"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#大体流程"}},[t._v("#")]),t._v(" 大体流程")]),t._v(" "),s("ol",[s("li",[t._v("抓取验证码")]),t._v(" "),s("li",[t._v("给验证码打标签")]),t._v(" "),s("li",[t._v("图片预处理")]),t._v(" "),s("li",[t._v("保存数据集")]),t._v(" "),s("li",[t._v("构建模型训练")]),t._v(" "),s("li",[t._v("提取模型使用")])]),t._v(" "),s("h2",{attrs:{id:"抓取验证码"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#抓取验证码"}},[t._v("#")]),t._v(" 抓取验证码")]),t._v(" "),s("p",[t._v("这个简单，随便什么方式，循环下载一大堆，这里不再赘述。我这里下载了 750 张验证码，用 500 张做训练，剩下 250 张验证模型效果。")]),t._v(" "),s("p",[s("img",{staticClass:"lazy",attrs:{alt:"","data-src":a(491),loading:"lazy"}})]),t._v(" "),s("h2",{attrs:{id:"给验证码打标签"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#给验证码打标签"}},[t._v("#")]),t._v(" 给验证码打标签")]),t._v(" "),s("p",[t._v("这里的验证码有750张之巨，要是手工给每个验证码打标签，那一定累尿了。这时候就可以使用人工打码服务，用廉价劳动力帮我们做这件事。人工打码后把识别结果保存下来。这里的代码就不提供了，看你用哪家的验证码服务，相信聪明的你一定能解决 😃")]),t._v(" "),s("p",[s("img",{staticClass:"lazy",attrs:{alt:"","data-src":a(492),loading:"lazy"}})]),t._v(" "),s("h2",{attrs:{id:"图片预处理"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#图片预处理"}},[t._v("#")]),t._v(" 图片预处理")]),t._v(" "),s("ol",[s("li",[s("strong",[t._v("图片信息：")]),t._v(" 此验证码是 68x23，JPG格式")]),t._v(" "),s("li",[s("strong",[t._v("二值化：")]),t._v(" 我确信这个验证码足够简单，在丢失图片的颜色信息后仍然能被很好的识别。并且可以降低模型复杂度，因此我们可以将图片二值化。即只有两个颜色，全黑或者全白。")]),t._v(" "),s("li",[s("strong",[t._v("切割验证码：")]),t._v(" 观察验证码，没有特别扭曲或者粘连，所以我们可以把验证码平均切割成4块，分别识别，这样图片识别模型就只需要处理10个分类（如果有字母那将是36个分类而已）由于验证码外面有一圈边框，所以顺带把边框也去掉了。")]),t._v(" "),s("li",[s("strong",[t._v("处理结果：")]),t._v(" 16x21，黑白2位")])]),t._v(" "),s("p",[t._v("相关 Python 代码如下：")]),t._v(" "),s("div",{staticClass:"language-python line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("img "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Image"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("open")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("file")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("convert"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'L'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 读取图片并灰度化")]),t._v("\n\nimg "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" img"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("crop"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("66")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("22")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 裁掉边变成 64x21")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 分离数字")]),t._v("\nimg1 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" img"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("crop"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("16")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("21")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nimg2 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" img"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("crop"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("16")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("32")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("21")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nimg3 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" img"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("crop"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("32")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("48")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("21")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nimg4 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" img"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("crop"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("48")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("64")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("21")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nimg1 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" np"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("array"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("img1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatten"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 扁平化，把二维弄成一维")]),t._v("\nimg1 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("list")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("map")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("lambda")]),t._v(" x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" x "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("180")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" img1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 二值化")]),t._v("\nimg2 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" np"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("array"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("img2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatten"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nimg2 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("list")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("map")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("lambda")]),t._v(" x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" x "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("180")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" img2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nimg3 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" np"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("array"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("img3"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatten"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nimg3 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("list")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("map")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("lambda")]),t._v(" x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" x "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("180")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" img3"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nimg4 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" np"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("array"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("img4"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatten"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nimg4 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("list")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("map")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("lambda")]),t._v(" x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" x "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("180")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" img4"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br"),s("span",{staticClass:"line-number"},[t._v("5")]),s("br"),s("span",{staticClass:"line-number"},[t._v("6")]),s("br"),s("span",{staticClass:"line-number"},[t._v("7")]),s("br"),s("span",{staticClass:"line-number"},[t._v("8")]),s("br"),s("span",{staticClass:"line-number"},[t._v("9")]),s("br"),s("span",{staticClass:"line-number"},[t._v("10")]),s("br"),s("span",{staticClass:"line-number"},[t._v("11")]),s("br"),s("span",{staticClass:"line-number"},[t._v("12")]),s("br"),s("span",{staticClass:"line-number"},[t._v("13")]),s("br"),s("span",{staticClass:"line-number"},[t._v("14")]),s("br"),s("span",{staticClass:"line-number"},[t._v("15")]),s("br"),s("span",{staticClass:"line-number"},[t._v("16")]),s("br"),s("span",{staticClass:"line-number"},[t._v("17")]),s("br"),s("span",{staticClass:"line-number"},[t._v("18")]),s("br")])]),s("h2",{attrs:{id:"保存数据集"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#保存数据集"}},[t._v("#")]),t._v(" 保存数据集")]),t._v(" "),s("p",[t._v("数据集有输入输入数据和标签数据，训练数据和测试数据。"),s("br"),t._v("\n因为数据量不大，简便起见，直接把数据存成python文件，供模型调用。就不保存为其他文件，然后用 "),s("em",[t._v("pandas")]),t._v(" 什么的来读取了。")]),t._v(" "),s("p",[t._v("最终我们的输入模型的数据形状为 "),s("strong",[t._v("[[0,1,0,1,0,1,0,1...],[0,1,0,1,0,1,0,1...],...]")]),s("br"),t._v("\n标签数据很特殊，本质上我们是对输入的数据进行分类，所以虽然标签应该是0到9的数字，但是这里我们使标签数据格式是 "),s("em",[t._v("one-hot vectors")]),t._v(" "),s("strong",[t._v("[[1,0,0,0,0,0,0,0,0,0,0],...]")]),s("br"),t._v("\n一个one-hot向量除了某一位的数字是1以外其余各维度数字都是0**，比如[1,0,0,0,0,0,0,0,0,0] 代表1，[0,1,0,0,0,0,0,0,0,0]代表2."),s("br"),t._v("\n更进一步，这里的 one-hot 向量其实代表着对应的数据分成这十类的概率。概率为1就是正确的分类。")]),t._v(" "),s("p",[t._v("相关 Python 代码如下：")]),t._v(" "),s("div",{staticClass:"language-python line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 保存输入数据")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("px")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("prefix"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" img1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" img2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" img3"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" img4"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("with")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("open")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'./data/'")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" prefix "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'_images.py'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'a+'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("img1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("file")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" end"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('",\\n"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("img2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("file")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" end"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('",\\n"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("img3"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("file")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" end"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('",\\n"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("img4"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("file")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" end"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('",\\n"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 保存标签数据")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("py")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("prefix"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" code"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("with")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("open")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'./data/'")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" prefix "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'_labels.py'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'a+'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" x "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("range")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            tmp "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n            tmp"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("int")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("code"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tmp"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("file")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" end"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('",\\n"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br"),s("span",{staticClass:"line-number"},[t._v("5")]),s("br"),s("span",{staticClass:"line-number"},[t._v("6")]),s("br"),s("span",{staticClass:"line-number"},[t._v("7")]),s("br"),s("span",{staticClass:"line-number"},[t._v("8")]),s("br"),s("span",{staticClass:"line-number"},[t._v("9")]),s("br"),s("span",{staticClass:"line-number"},[t._v("10")]),s("br"),s("span",{staticClass:"line-number"},[t._v("11")]),s("br"),s("span",{staticClass:"line-number"},[t._v("12")]),s("br"),s("span",{staticClass:"line-number"},[t._v("13")]),s("br"),s("span",{staticClass:"line-number"},[t._v("14")]),s("br"),s("span",{staticClass:"line-number"},[t._v("15")]),s("br")])]),s("p",[t._v("经过上面两步，我们在就获得了训练和测试用的数据和标签数据，呐，就像这样")]),t._v(" "),s("p",[s("img",{staticClass:"lazy",attrs:{alt:"","data-src":a(493),loading:"lazy"}})]),t._v(" "),s("h2",{attrs:{id:"构建模型训练"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#构建模型训练"}},[t._v("#")]),t._v(" 构建模型训练")]),t._v(" "),s("p",[t._v("数据准备好啦，到了要搭建“管道”的时候了。"),s("br"),t._v("\n也就是你需要告诉 TensorFlow：")]),t._v(" "),s("h3",{attrs:{id:"_1-输入数据的形状是怎样的"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1-输入数据的形状是怎样的"}},[t._v("#")]),t._v(" 1. 输入数据的形状是怎样的？")]),t._v(" "),s("div",{staticClass:"language-python line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("x "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("placeholder"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("float32"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" DLEN"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br")])]),s("p",[t._v("None 表示不定义我们有多少训练数据，DLEN是 16*21，即一维化的图片的大小。")]),t._v(" "),s("h3",{attrs:{id:"_2-输出数据的形状是怎样的"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-输出数据的形状是怎样的"}},[t._v("#")]),t._v(" 2. 输出数据的形状是怎样的？")]),t._v(" "),s("div",{staticClass:"language-python line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("y_ "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("placeholder"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"float"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br")])]),s("p",[t._v("同样None 表示不定义我们有多少训练数据，10 就是标签数据的维度，即图片有 10 个分类。每个分类对应着一个概率，所以是浮点类型。")]),t._v(" "),s("h3",{attrs:{id:"_3-输入数据-模型-标签数据怎样拟合"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-输入数据-模型-标签数据怎样拟合"}},[t._v("#")]),t._v(" 3. 输入数据，模型，标签数据怎样拟合？")]),t._v(" "),s("div",{staticClass:"language-python line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("W "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Variable"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("zeros"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("DLEN"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 权重")]),t._v("\nb "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Variable"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("zeros"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 偏置")]),t._v("\n\ny "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("softmax"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("matmul"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" W"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br")])]),s("p",[t._v("是不是一个很简单的模型？大体就是"),s("br"),t._v(" "),s("strong",[t._v("y = softmax(Wx+b)")]),s("br"),t._v("\n其中 W 和 b 是 TensorFlow 中的变量，他们保存着模型在训练过程中的数据，需要定义出来。而我们模型训练的目的，也就是把 W 和 b 的值确定，使得这个式子可以更好的拟合数据。"),s("br"),t._v(" "),s("em",[t._v("softmax")]),t._v(" 是所谓的激活函数，把线性的结果转换成我们需要的样式，也就是分类概率的分布。"),s("br"),t._v("\n关于 "),s("em",[t._v("softmax")]),t._v(" 之类更多解释请查看参考链接。")]),t._v(" "),s("h3",{attrs:{id:"_4-怎样评估模型的好坏"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_4-怎样评估模型的好坏"}},[t._v("#")]),t._v(" 4. 怎样评估模型的好坏？")]),t._v(" "),s("p",[t._v("模型训练就是为了使模型输出结果和实际情况相差尽可能小。所以要定义评估方式。"),s("br"),t._v("\n这里用所谓的"),s("em",[t._v("交叉熵")]),t._v("来评估。")]),t._v(" "),s("div",{staticClass:"language-python line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("cross_entropy "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("tf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reduce_sum"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("y_"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("tf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("log"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("y"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br")])]),s("h3",{attrs:{id:"_5-怎样最小化误差"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_5-怎样最小化误差"}},[t._v("#")]),t._v(" 5. 怎样最小化误差？")]),t._v(" "),s("p",[t._v("现在 TensorFlow 已经知道了足够的信息，它要做的工作就是让模型的误差足够小，它会使出各种方法使上面定义的交叉熵 "),s("em",[t._v("cross_entropy")]),t._v(" 变得尽可能小。"),s("br"),t._v("\nTensorFlow 内置了不少方式可以达到这个目的，不同方式有不同的特点和适用条件。在这里使用梯度下降法来实现这个目的。")]),t._v(" "),s("div",{staticClass:"language-python line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("train_step "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("train"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("GradientDescentOptimizer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.01")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("minimize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cross_entropy"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br")])]),s("h3",{attrs:{id:"训练准备"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#训练准备"}},[t._v("#")]),t._v(" 训练准备")]),t._v(" "),s("p",[t._v("大家知道 Python 作为解释型语言，运行效率不能算是太好，而这种机器学习基本是需要大量计算力的场合。TensorFlow 在底层是用 C++ 写就，在 Python 端只是一个操作端口，所有的计算都要交给底层处理。这自然就引出了"),s("strong",[t._v("会话")]),t._v("的概念，底层和调用层需要通信。也正是这个特点，TensorFlow 支持很多其他语言接入，如 Java, C，而不仅仅是 Python。"),s("br"),t._v("\n和底层通信是通过会话完成的。我们可以通过一行代码来启动会话：")]),t._v(" "),s("div",{staticClass:"language-python line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("sess "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Session"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 代码...")]),t._v("\nsess"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("close"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br")])]),s("p",[t._v("别忘了在使用完后关闭会话。当然你也可以使用 Python 的 "),s("em",[t._v("with")]),t._v(" 语句来自动管理。")]),t._v(" "),s("p",[t._v("在 TensorFlow 中，变量都是需要在会话启动之后初始化才能使用。")]),t._v(" "),s("div",{staticClass:"language-python line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("sess"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("run"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("global_variables_initializer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br")])]),s("h3",{attrs:{id:"开始训练"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#开始训练"}},[t._v("#")]),t._v(" 开始训练")]),t._v(" "),s("div",{staticClass:"language-python line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" i "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("range")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("DNUM"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    batch_xs "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("train_images"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    batch_ys "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("train_labels"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    sess"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("run"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("train_step"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" feed_dict"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" batch_xs"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y_"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" batch_ys"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br")])]),s("p",[t._v("我们把模型和训练数据交给会话，底层就自动帮我们处理啦。"),s("br"),t._v("\n我们可以一次传入任意数量数据给模型（上面设置None的作用），为了训练效果，可以适当调节每一批次训练的数据。甚至于有时候还要随机选择数据以获得更好的训练效果。在这里我们就一条一条训练了，反正最后效果还可以。要了解更多可以查看参考链接。")]),t._v(" "),s("h3",{attrs:{id:"检验训练结果"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#检验训练结果"}},[t._v("#")]),t._v(" 检验训练结果")]),t._v(" "),s("p",[t._v("这里我们的测试数据就要派上用场了")]),t._v(" "),s("div",{staticClass:"language-python line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("correct_prediction "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("equal"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("argmax"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("y"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" tf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("argmax"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("y_"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\naccuracy "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reduce_mean"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cast"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("correct_prediction"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"float"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sess"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("run"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("accuracy"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" feed_dict"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" test_images"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y_"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" test_labels"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br")])]),s("p",[t._v("我们模型输出是一个数组，里面存着每个分类的概率，所以我们要拿出概率最大的分类和测试标签比较。看在这 250 条测试数据里面，正确率是多少。当然这些也是定义完操作步骤，交给会话来运行处理的。"),s("br"),t._v(" "),s("img",{staticClass:"lazy",attrs:{alt:"","data-src":a(494),loading:"lazy"}})]),t._v(" "),s("h2",{attrs:{id:"提取模型使用"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#提取模型使用"}},[t._v("#")]),t._v(" 提取模型使用")]),t._v(" "),s("p",[t._v("在上面我们已经把模型训练好了，而且效果还不错哦，近 99% 的正确率，或许比人工打码还高一些呢（获取测试数据时候常常返回有错误的值）。但是问题来了，我现在要把这个模型用于生产怎么办，总不可能每次都训练一次吧。在这里，我们就要使用到 TensorFlow 的模型保存和载入功能了。")]),t._v(" "),s("h3",{attrs:{id:"保存模型"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#保存模型"}},[t._v("#")]),t._v(" 保存模型")]),t._v(" "),s("p",[t._v("先在模型训练的时候保存模型，定义一个 saver，然后直接把会话保存到一个目录就好了。")]),t._v(" "),s("div",{staticClass:"language-python line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("saver "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("train"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Saver"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 训练代码")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# ...")]),t._v("\nsaver"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("save"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sess"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'model/model'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nsess"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("close"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br"),s("span",{staticClass:"line-number"},[t._v("5")]),s("br")])]),s("p",[t._v("当然这里的 saver 也有不少配置，比如保存最近多少批次的训练结果之类，可以自行查资料。")]),t._v(" "),s("h2",{attrs:{id:"恢复模型"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#恢复模型"}},[t._v("#")]),t._v(" 恢复模型")]),t._v(" "),s("p",[t._v("同样恢复模型也很简单")]),t._v(" "),s("div",{staticClass:"language-python line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("saver"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("restore"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sess"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"model/model"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br")])]),s("p",[t._v("当然你还是需要定义好模型，才能恢复。我的理解是这里模型保存的是训练过程中各个变量的值，权重偏置什么的，所以结构架子还是要事先搭好才行。"),s("br"),t._v(" "),s("img",{staticClass:"lazy",attrs:{alt:"","data-src":a(495),loading:"lazy"}})]),t._v(" "),s("h2",{attrs:{id:"最后"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#最后"}},[t._v("#")]),t._v(" 最后")]),t._v(" "),s("p",[t._v("这里只是展示了使用 TensorFlow 识别简单的验证码，效果还不错，上机器学习应该也不算是杀鸡用牛刀。毕竟模型无脑，节省很多时间。如果需要识别更加扭曲，更加变态的验证码，或许需要上卷积神经网络之类，图片结构和颜色信息都不能丢掉了。另一方面，做网站安全这块，纯粹的图形验证码恐怕不能作为判断是不是机器人的依据。对抗到最后，就变成这样的变态验证码哈哈哈。"),s("br"),t._v(" "),s("img",{staticClass:"lazy",attrs:{alt:"","data-src":a(496),loading:"lazy"}})]),t._v(" "),s("h2",{attrs:{id:"相关链接"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#相关链接"}},[t._v("#")]),t._v(" 相关链接")]),t._v(" "),s("ol",[s("li",[s("a",{attrs:{href:"https://github.com/purocean/tensorflow-simple-captcha",target:"_blank",rel:"noopener noreferrer"}},[t._v("https://github.com/purocean/tensorflow-simple-captcha"),s("OutboundLink")],1)]),t._v(" "),s("li",[s("a",{attrs:{href:"https://keras-cn.readthedocs.io/en/latest/for_beginners/concepts/",target:"_blank",rel:"noopener noreferrer"}},[t._v("https://keras-cn.readthedocs.io/en/latest/for_beginners/concepts/"),s("OutboundLink")],1)]),t._v(" "),s("li",[s("a",{attrs:{href:"http://wiki.jikexueyuan.com/project/tensorflow-zh/",target:"_blank",rel:"noopener noreferrer"}},[t._v("http://wiki.jikexueyuan.com/project/tensorflow-zh/"),s("OutboundLink")],1)])])])}),[],!1,null,null,null);s.default=e.exports}}]);